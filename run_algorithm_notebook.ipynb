{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:55:11.878656100Z",
     "start_time": "2023-09-25T21:36:33.199269900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from negex import *\n",
    "from support_functions import *\n",
    "from argparse import ArgumentParser\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def run_taggers(substr, suicidal_ideation, phrase_list, plan_phrases, intent_phrases, these_rules, \\\n",
    "                hist_rules, plan_rules):\n",
    "    neg = False\n",
    "    pos = False\n",
    "    plan = False\n",
    "    intent = False\n",
    "    neg_hist = False\n",
    "    pos_hist = False\n",
    "\n",
    "    tagger = negTagger(sentence=substr, phrases=phrase_list, rules=these_rules, negP=False)\n",
    "    hist_tagger = negTagger(sentence=substr, phrases=phrase_list, rules=hist_rules, negP=False)\n",
    "\n",
    "    if tagger.getNegationFlag() == 'negated':\n",
    "        neg = True\n",
    "\n",
    "    else:\n",
    "        if '[PHRASE]' in tagger.getNegTaggedSentence():\n",
    "            pos = True\n",
    "        if suicidal_ideation == True:\n",
    "            tagger2 = negTagger(sentence=substr, phrases=plan_phrases, rules=plan_rules, negP=False)\n",
    "            if '[PHRASE]' in tagger2.getNegTaggedSentence() and tagger2.getNegationFlag() == 'affirmed':\n",
    "                plan = True\n",
    "\n",
    "            tagger3 = negTagger(sentence=substr, phrases=intent_phrases, rules=plan_rules, negP=False)\n",
    "            if '[PHRASE]' in tagger3.getNegTaggedSentence() and tagger3.getNegationFlag() == 'affirmed':\n",
    "                intent = True\n",
    "\n",
    "    if hist_tagger.getNegationFlag() == 'negated':\n",
    "        neg_hist = True\n",
    "    else:\n",
    "        if '[PHRASE]' in hist_tagger.getNegTaggedSentence():\n",
    "            pos_hist = True\n",
    "\n",
    "    #if suicidal_ideation == True:\n",
    "    #return pos,pos_hist, neg,neg_hist, plan, intent\n",
    "    # else:\n",
    "    return pos, pos_hist, neg, neg_hist, plan, intent\n",
    "\n",
    "\n",
    "def run_portion(this_text, sentence_breaks, phrase_list, phrase_list2, suicidal_ideation, intent_phrases, plan_phrases):\n",
    "    neg_mention = set()\n",
    "    neg_hist_mention = set()\n",
    "    pos_mention = set()\n",
    "    pos_hist_mention = set()\n",
    "    plan_mention = set()\n",
    "    intent_mention = set()\n",
    "\n",
    "    indices = set()\n",
    "    for s in phrase_list2:\n",
    "        if this_text.find(s) != -1:\n",
    "            all_idx = find_all_indexes(this_text, s)\n",
    "            for j in all_idx:\n",
    "                indices.add(j)\n",
    "    indices = sorted(list(indices))\n",
    "\n",
    "    for idx, places in enumerate(indices):\n",
    "        next_break = list(filter(lambda x: x > indices[idx], sentence_breaks))[0]\n",
    "        break_index = np.where(np.array(sentence_breaks) == next_break)[0][0]\n",
    "\n",
    "        if this_text[next_break] == ':' or this_text[next_break] == '?':\n",
    "\n",
    "            list_of_words = this_text[next_break:].split()\n",
    "            max_length = min(len(list_of_words) - 1, 3)\n",
    "\n",
    "            space = this_text.find(list_of_words[max_length], next_break) + len(list_of_words[max_length])\n",
    "\n",
    "            substr = this_text[sentence_breaks[break_index - 1]: space]\n",
    "            if suicidal_ideation == True:\n",
    "\n",
    "                pos, pos_hist, neg, neg_hist, plan, intent = run_taggers(substr, suicidal_ideation, phrase_list,\n",
    "                                                                         plan_phrases, intent_phrases, irules3, irules8,\n",
    "                                                                         irules4)\n",
    "\n",
    "\n",
    "            else:\n",
    "                pos, pos_hist, neg, neg_hist, plan, intent = run_taggers(substr, suicidal_ideation, phrase_list,\n",
    "                                                                         plan_phrases, intent_phrases, irules6,\n",
    "                                                                         irules10, irules4)\n",
    "\n",
    "            if pos == True:\n",
    "                pos_mention.add(substr)\n",
    "            if pos_hist == True:\n",
    "                pos_hist_mention.add(substr)\n",
    "            if neg == True:\n",
    "                neg_mention.add(substr)\n",
    "            if neg_hist == True:\n",
    "                neg_hist_mention.add(substr)\n",
    "            if plan == True:\n",
    "                plan_mention.add(substr)\n",
    "            if intent == True:\n",
    "                intent_mention.add(substr)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            substr = this_text[sentence_breaks[break_index - 1]: next_break + 1]\n",
    "\n",
    "            if suicidal_ideation == True:\n",
    "                pos, pos_hist, neg, neg_hist, plan, intent = run_taggers(substr, suicidal_ideation, phrase_list,\n",
    "                                                                         plan_phrases, intent_phrases, irules, irules7,\n",
    "                                                                         irules4)\n",
    "\n",
    "            else:\n",
    "                pos, pos_hist, neg, neg_hist, plan, intent = run_taggers(substr, suicidal_ideation, phrase_list,\n",
    "                                                                         plan_phrases, intent_phrases, irules5, irules7,\n",
    "                                                                         irules4)\n",
    "\n",
    "            if pos == True:\n",
    "                pos_mention.add(substr)\n",
    "            if pos_hist == True:\n",
    "                pos_hist_mention.add(substr)\n",
    "            if neg == True:\n",
    "                neg_mention.add(substr)\n",
    "            if neg_hist == True:\n",
    "                neg_hist_mention.add(substr)\n",
    "            if plan == True:\n",
    "                plan_mention.add(substr)\n",
    "            if intent == True:\n",
    "                intent_mention.add(substr)\n",
    "\n",
    "    if suicidal_ideation == True:\n",
    "        return neg_mention, neg_hist_mention, pos_mention, pos_hist_mention, intent_mention, plan_mention\n",
    "    else:\n",
    "        return neg_mention, neg_hist_mention, pos_mention, pos_hist_mention\n",
    "\n",
    "\n",
    "def run_algorithm(dataframe, note_c, breaks, SI_phrases, SI_phrases2, SB_phrases, SB_phrases2, intent_phrases,\n",
    "                  plan_phrases):\n",
    "    pos_SImention = [set() for i in range(len(dataframe))]\n",
    "    neg_SImention = [set() for i in range(len(dataframe))]\n",
    "    plan_SImention = [set() for i in range(len(dataframe))]\n",
    "    intent_SImention = [set() for i in range(len(dataframe))]\n",
    "\n",
    "    pos_histSImention = [set() for i in range(len(dataframe))]\n",
    "    neg_histSImention = [set() for i in range(len(dataframe))]\n",
    "\n",
    "    pos_SBmention = [set() for i in range(len(dataframe))]\n",
    "    neg_SBmention = [set() for i in range(len(dataframe))]\n",
    "\n",
    "    pos_histSBmention = [set() for i in range(len(dataframe))]\n",
    "    neg_histSBmention = [set() for i in range(len(dataframe))]\n",
    "\n",
    "    predSI_intent = [0 for i in range(len(dataframe))]\n",
    "    predSI_plan = [0 for i in range(len(dataframe))]\n",
    "    predSI = [0 for i in range(len(dataframe))]\n",
    "    predSB = [0 for i in range(len(dataframe))]\n",
    "\n",
    "    predhistSI = [0 for i in range(len(dataframe))]\n",
    "    predhistSB = [0 for i in range(len(dataframe))]\n",
    "\n",
    "    not_relevant = [0 for i in range(len(dataframe))]\n",
    "\n",
    "    for i in range(len(dataframe)):\n",
    "        this_text = dataframe[note_c].iloc[i].lower()\n",
    "\n",
    "        #translator = str.maketrans(our_punct, ' '*len(our_punct))\n",
    "        #this_text = this_text.translate(translator)\n",
    "\n",
    "        this_text = preprocess_note2(this_text)\n",
    "\n",
    "        sentence_breaks = set()\n",
    "        for b in breaks:\n",
    "            if this_text.find(b) != -1:\n",
    "                all_b = find_all_indexes(this_text, b)\n",
    "                for j in all_b:\n",
    "                    sentence_breaks.add(j)\n",
    "\n",
    "        sentence_breaks = sorted(list(sentence_breaks))\n",
    "        sentence_breaks.insert(0, 0)\n",
    "        sentence_breaks.append(len(this_text) - 1)\n",
    "\n",
    "        neg_SImention[i], neg_histSImention[i], pos_SImention[i], pos_histSImention[i], intent_SImention[i], \\\n",
    "        plan_SImention[i] = run_portion(this_text, sentence_breaks, SI_phrases, SI_phrases2, True, intent_phrases,\n",
    "                                        plan_phrases)\n",
    "\n",
    "        neg_SBmention[i], neg_histSBmention[i], pos_SBmention[i], pos_histSBmention[i] = run_portion(this_text,\n",
    "                                                                                                     sentence_breaks,\n",
    "                                                                                                     SB_phrases,\n",
    "                                                                                                     SB_phrases2, False,\n",
    "                                                                                                     intent_phrases,\n",
    "                                                                                                     plan_phrases)\n",
    "\n",
    "        if len(pos_SImention[i]) > 0:\n",
    "            predSI[i] = 1\n",
    "\n",
    "        if len(pos_histSImention[i]) > 0:\n",
    "            predhistSI[i] = 1\n",
    "\n",
    "        if len(pos_SBmention[i]) > 0:\n",
    "            predSB[i] = 1\n",
    "\n",
    "        if len(pos_histSBmention[i]) > 0:\n",
    "            predhistSB[i] = 1\n",
    "\n",
    "        if len(intent_SImention[i]) > 0:\n",
    "            predSI_intent[i] = 1\n",
    "        if len(plan_SImention[i]) > 0:\n",
    "            predSI_plan[i] = 1\n",
    "\n",
    "        if len(neg_SImention[i]) == 0 and len(pos_SImention[i]) == 0 and len(neg_SBmention[i]) == 0 and len(\n",
    "                pos_SBmention[i]) == 0:\n",
    "            not_relevant[i] = 1\n",
    "\n",
    "    dataframe['predSI'] = pd.Series(predSI, index=dataframe.index)\n",
    "    dataframe['predhistSI'] = pd.Series(predhistSI, index=dataframe.index)\n",
    "\n",
    "    dataframe['pos_SI_men'] = pd.Series(pos_SImention, index=dataframe.index)\n",
    "    dataframe['neg_SI_men'] = pd.Series(neg_SImention, index=dataframe.index)\n",
    "\n",
    "    dataframe['pos_SI_hist_men'] = pd.Series(pos_histSImention, index=dataframe.index)\n",
    "    dataframe['neg_SI_hist_men'] = pd.Series(neg_histSImention, index=dataframe.index)\n",
    "\n",
    "    dataframe['plan_SImention'] = pd.Series(plan_SImention, index=dataframe.index)\n",
    "    dataframe['predSI_plan'] = pd.Series(predSI_plan, index=dataframe.index)\n",
    "    dataframe['intent_SImention'] = pd.Series(intent_SImention, index=dataframe.index)\n",
    "    dataframe['predSI_intent'] = pd.Series(predSI_intent, index=dataframe.index)\n",
    "\n",
    "    dataframe['pos_SB_men'] = pd.Series(pos_SBmention, index=dataframe.index)\n",
    "    dataframe['neg_SB_men'] = pd.Series(neg_SBmention, index=dataframe.index)\n",
    "\n",
    "    dataframe['pos_SB_hist_men'] = pd.Series(pos_histSBmention, index=dataframe.index)\n",
    "    dataframe['neg_SB_hist_men'] = pd.Series(neg_histSBmention, index=dataframe.index)\n",
    "\n",
    "    dataframe['predSB'] = pd.Series(predSB, index=dataframe.index)\n",
    "    dataframe['predhistSB'] = pd.Series(predhistSB, index=dataframe.index)\n",
    "\n",
    "    dataframe['not_relevant'] = pd.Series(not_relevant, index=dataframe.index)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "with open('SI_Files/full_si_phrases.txt') as f:\n",
    "    content = f.readlines()\n",
    "SI_phrases = [x.strip() for x in content]\n",
    "\n",
    "with open('SI_Files/full_si_phrases2.txt') as f:\n",
    "    content = f.readlines()\n",
    "SI_phrases2 = [x.strip() for x in content]\n",
    "\n",
    "with open('SI_Files/full_sb_phrases.txt') as f:\n",
    "    content = f.readlines()\n",
    "SB_phrases = [x.strip() for x in content]\n",
    "\n",
    "with open('SI_Files/full_sb_phrases2.txt') as f:\n",
    "    content = f.readlines()\n",
    "SB_phrases2 = [x.strip() for x in content]\n",
    "\n",
    "with open('SI_Files/plan_phrases.txt') as f:\n",
    "    content = f.readlines()\n",
    "plan_phrases = [x.strip() for x in content]\n",
    "\n",
    "with open('SI_Files/intent_phrases.txt') as f:\n",
    "    content = f.readlines()\n",
    "intent_phrases = [x.strip() for x in content]\n",
    "\n",
    "breaks = ['.', '?', ':']\n",
    "\n",
    "rfile = open(r'NegexRules2/SI_natural.txt')\n",
    "irules = sortRules(rfile.readlines())\n",
    "ifile3 = open(r'NegexRules2/SI_post_rules.txt')\n",
    "irules3 = sortRules(ifile3.readlines())\n",
    "ifile4 = open(r'NegexRules2/SI_Intent.txt')\n",
    "irules4 = sortRules(ifile4.readlines())\n",
    "\n",
    "rfile5 = open(r'NegexRules2/SB_natural.txt')\n",
    "irules5 = sortRules(rfile5.readlines())\n",
    "ifile6 = open(r'NegexRules2/SB_post_rules.txt')\n",
    "irules6 = sortRules(ifile6.readlines())\n",
    "\n",
    "rfile7 = open(r'NegexRules2/SI_natural_hist.txt')\n",
    "irules7 = sortRules(rfile7.readlines())\n",
    "ifile8 = open(r'NegexRules2/SI_post_hist_rules.txt')\n",
    "irules8 = sortRules(ifile8.readlines())\n",
    "\n",
    "rfile9 = open(r'NegexRules2/SB_natural_hist.txt')\n",
    "irules9 = sortRules(rfile9.readlines())\n",
    "ifile10 = open(r'NegexRules2/SB_post_hist_rules.txt')\n",
    "irules10 = sortRules(ifile10.readlines())\n",
    "\n",
    "# parser = ArgumentParser()\n",
    "# parser.add_argument(\"-d\", dest = \"data_path\", required = True, help = \"data path to read in\")\n",
    "# parser.add_argument(\"-nc\", dest = \"note_text_column\", required = True, help = \"name of note text column\")\n",
    "# parser.add_argument(\"-s\", dest = \"save_path\", required = True, help = \"data path to save to\")\n",
    "#\n",
    "# args = parser.parse_args()\n",
    "# data_p = args.data_path\n",
    "# note_c = args.note_text_column\n",
    "# save_p = args.save_path\n",
    "\n",
    "note_c = \"NOTE_TEXT\"\n",
    "\n",
    "#df = pd.read_excel(data_p)\n",
    "# df = pd.read_csv (data_p)\n",
    "# os.chdir(r'C:\\si_ideation_IH\\si_ideation\\sql')\n",
    "\n",
    "conn = sqlite3.connect(\"notes_DB.db\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "#pull data from sqlite database\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "\n",
    "SELECT *\n",
    "FROM si_data_all_clean\n",
    "\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "df.NOTE_TEXT = df.NOTE_TEXT.astype(str)  #tells what type of data to expect\n",
    "\n",
    "df = run_algorithm(df, note_c, breaks, SI_phrases, SI_phrases2, SB_phrases, SB_phrases2, intent_phrases, plan_phrases)\n",
    "\n",
    "#df.to_excel(save_p, index = False)\n",
    "# df.to_csv(save_p) #edited to save to csv instead of xlsx\n",
    "\n",
    "# df.to_sql(name=\"si_data_results\", con=conn, if_exists='append', index=False)\n",
    "\n",
    "print(df['predSI'].value_counts())\n",
    "print(df['predhistSI'].value_counts())\n",
    "\n",
    "print(df['predSB'].value_counts())\n",
    "print(df['predhistSB'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:55:30.724774500Z",
     "start_time": "2023-09-25T21:55:25.883362600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:55:59.305940800Z",
     "start_time": "2023-09-25T21:55:35.927568200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_sql(name=\"si_data_results\", con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:56:03.814953500Z",
     "start_time": "2023-09-25T21:56:03.730843300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_case = df[df.case_flg == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:56:06.926726100Z",
     "start_time": "2023-09-25T21:56:06.645659Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case = df_case.groupby('person_mk')['not_relevant'].min().reset_index()\n",
    "case['pred'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:56:13.404540100Z",
     "start_time": "2023-09-25T21:56:13.386507700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case.not_relevant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-25T21:56:18.928755500Z",
     "start_time": "2023-09-25T21:56:18.832013900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(case['pred'], case['not_relevant']))\n",
    "# print(confusion_matrix(case['pred'], case['not_relevant']))\n",
    "print(accuracy_score(case['pred'], case['not_relevant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T19:12:18.153661900Z",
     "start_time": "2023-09-22T19:12:18.102665800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
